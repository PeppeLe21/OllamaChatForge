# OllamaChatForge

## ENG

Welcome to the OllamaChatForge project! This repository contains the code for both the back-end and the front-end of the application. Below are instructions on how to set up and run the application on your local machine.

### Prerequisites

Before getting started, make sure you have the following tools installed on your system:

- [Ollama](https://ollama.com) (for using language models)
- [Python](https://www.python.org/downloads/) (for running the back-end)
- [Flutter](https://flutter.dev/docs/get-started/install) (for running the front-end)

### Ollama Installation and Setup

Ensure that Ollama is installed and running properly before starting the back-end of the application. This is necessary for the correct functioning of the language models within the application.

### Back-End Setup

To run the back-end, you need to start the FastAPI server. Follow these steps:

1. Navigate to the directory containing the back-end code.
2. Install the required Python packages by running:

   ```bash
   pip install -r requirements.txt
